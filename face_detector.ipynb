{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2023 The MediaPipe Authors. All Rights Reserved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_cQX8dWu4Dv"
      },
      "source": [
        "# Face Detection with MediaPipe Tasks\n",
        "\n",
        "This notebook shows you how to use the MediaPipe Tasks Python API to detect faces in images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6PN9FvIx614"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "Let's start with installing MediaPipe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gxbHBsF-8Y_l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.10.11-cp38-cp38-win_amd64.whl.metadata (9.8 kB)\n",
            "Collecting absl-py (from mediapipe)\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting attrs>=19.1.0 (from mediapipe)\n",
            "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting flatbuffers>=2.0 (from mediapipe)\n",
            "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
            "Collecting jax (from mediapipe)\n",
            "  Downloading jax-0.4.13.tar.gz (1.3 MB)\n",
            "     ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
            "     -- ------------------------------------- 0.1/1.3 MB 2.6 MB/s eta 0:00:01\n",
            "     -------------- ------------------------- 0.5/1.3 MB 6.0 MB/s eta 0:00:01\n",
            "     ---------------------------------------- 1.3/1.3 MB 11.9 MB/s eta 0:00:00\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "  Preparing metadata (pyproject.toml): started\n",
            "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
            "Requirement already satisfied: matplotlib in c:\\users\\felicia\\.conda\\envs\\vclip\\lib\\site-packages (from mediapipe) (3.7.5)\n",
            "Requirement already satisfied: numpy in c:\\users\\felicia\\.conda\\envs\\vclip\\lib\\site-packages (from mediapipe) (1.24.4)\n",
            "Collecting opencv-contrib-python (from mediapipe)\n",
            "  Using cached opencv_contrib_python-4.9.0.80-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
            "Collecting protobuf<4,>=3.11 (from mediapipe)\n",
            "  Downloading protobuf-3.20.3-cp38-cp38-win_amd64.whl.metadata (699 bytes)\n",
            "Collecting sounddevice>=0.4.4 (from mediapipe)\n",
            "  Downloading sounddevice-0.4.6-py3-none-win_amd64.whl.metadata (1.4 kB)\n",
            "Collecting CFFI>=1.0 (from sounddevice>=0.4.4->mediapipe)\n",
            "  Using cached cffi-1.16.0-cp38-cp38-win_amd64.whl.metadata (1.5 kB)\n",
            "Collecting ml-dtypes>=0.1.0 (from jax->mediapipe)\n",
            "  Downloading ml_dtypes-0.2.0-cp38-cp38-win_amd64.whl.metadata (20 kB)\n",
            "Collecting opt-einsum (from jax->mediapipe)\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: scipy>=1.7 in c:\\users\\felicia\\.conda\\envs\\vclip\\lib\\site-packages (from jax->mediapipe) (1.10.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\felicia\\.conda\\envs\\vclip\\lib\\site-packages (from jax->mediapipe) (7.0.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\felicia\\.conda\\envs\\vclip\\lib\\site-packages (from matplotlib->mediapipe) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\felicia\\.conda\\envs\\vclip\\lib\\site-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\felicia\\.conda\\envs\\vclip\\lib\\site-packages (from matplotlib->mediapipe) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\felicia\\.conda\\envs\\vclip\\lib\\site-packages (from matplotlib->mediapipe) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\felicia\\.conda\\envs\\vclip\\lib\\site-packages (from matplotlib->mediapipe) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\felicia\\.conda\\envs\\vclip\\lib\\site-packages (from matplotlib->mediapipe) (10.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\felicia\\.conda\\envs\\vclip\\lib\\site-packages (from matplotlib->mediapipe) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\felicia\\.conda\\envs\\vclip\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\felicia\\.conda\\envs\\vclip\\lib\\site-packages (from matplotlib->mediapipe) (6.4.0)\n",
            "Collecting pycparser (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe)\n",
            "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\felicia\\.conda\\envs\\vclip\\lib\\site-packages (from importlib-metadata>=4.6->jax->mediapipe) (3.17.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\felicia\\.conda\\envs\\vclip\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
            "Downloading mediapipe-0.10.11-cp38-cp38-win_amd64.whl (50.8 MB)\n",
            "   ---------------------------------------- 0.0/50.8 MB ? eta -:--:--\n",
            "    --------------------------------------- 0.6/50.8 MB 13.5 MB/s eta 0:00:04\n",
            "   - -------------------------------------- 1.3/50.8 MB 14.2 MB/s eta 0:00:04\n",
            "   - -------------------------------------- 2.0/50.8 MB 14.1 MB/s eta 0:00:04\n",
            "   -- ------------------------------------- 2.7/50.8 MB 14.4 MB/s eta 0:00:04\n",
            "   -- ------------------------------------- 3.5/50.8 MB 14.8 MB/s eta 0:00:04\n",
            "   --- ------------------------------------ 4.2/50.8 MB 14.9 MB/s eta 0:00:04\n",
            "   --- ------------------------------------ 5.0/50.8 MB 15.2 MB/s eta 0:00:04\n",
            "   ---- ----------------------------------- 5.8/50.8 MB 15.5 MB/s eta 0:00:03\n",
            "   ----- ---------------------------------- 6.7/50.8 MB 15.8 MB/s eta 0:00:03\n",
            "   ----- ---------------------------------- 7.6/50.8 MB 16.2 MB/s eta 0:00:03\n",
            "   ------ --------------------------------- 8.6/50.8 MB 16.6 MB/s eta 0:00:03\n",
            "   ------- -------------------------------- 9.7/50.8 MB 17.2 MB/s eta 0:00:03\n",
            "   -------- ------------------------------- 10.7/50.8 MB 17.7 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 11.8/50.8 MB 18.7 MB/s eta 0:00:03\n",
            "   ---------- ----------------------------- 12.8/50.8 MB 19.8 MB/s eta 0:00:02\n",
            "   ---------- ----------------------------- 13.8/50.8 MB 20.5 MB/s eta 0:00:02\n",
            "   ----------- ---------------------------- 14.9/50.8 MB 21.8 MB/s eta 0:00:02\n",
            "   ------------ --------------------------- 16.1/50.8 MB 22.6 MB/s eta 0:00:02\n",
            "   ------------- -------------------------- 17.5/50.8 MB 24.2 MB/s eta 0:00:02\n",
            "   --------------- ------------------------ 19.2/50.8 MB 24.2 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 20.5/50.8 MB 25.2 MB/s eta 0:00:02\n",
            "   ----------------- ---------------------- 22.3/50.8 MB 26.2 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 23.7/50.8 MB 27.3 MB/s eta 0:00:01\n",
            "   ------------------- -------------------- 25.2/50.8 MB 27.3 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 27.1/50.8 MB 29.7 MB/s eta 0:00:01\n",
            "   ---------------------- ----------------- 28.5/50.8 MB 29.7 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 30.0/50.8 MB 31.2 MB/s eta 0:00:01\n",
            "   ------------------------ --------------- 31.4/50.8 MB 31.2 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 33.0/50.8 MB 31.2 MB/s eta 0:00:01\n",
            "   --------------------------- ------------ 34.6/50.8 MB 32.8 MB/s eta 0:00:01\n",
            "   ---------------------------- ----------- 36.3/50.8 MB 32.7 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 37.8/50.8 MB 32.7 MB/s eta 0:00:01\n",
            "   ------------------------------- -------- 39.5/50.8 MB 34.4 MB/s eta 0:00:01\n",
            "   -------------------------------- ------- 41.1/50.8 MB 34.4 MB/s eta 0:00:01\n",
            "   --------------------------------- ------ 42.8/50.8 MB 34.6 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 44.5/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ------------------------------------ --- 46.2/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 47.9/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 49.4/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  50.8/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  50.8/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  50.8/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  50.8/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  50.8/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  50.8/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  50.8/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  50.8/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  50.8/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  50.8/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  50.8/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  50.8/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  50.8/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------  50.8/50.8 MB 36.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 50.8/50.8 MB 10.7 MB/s eta 0:00:00\n",
            "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
            "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Downloading protobuf-3.20.3-cp38-cp38-win_amd64.whl (904 kB)\n",
            "   ---------------------------------------- 0.0/904.4 kB ? eta -:--:--\n",
            "   --------------------------------------- 904.4/904.4 kB 28.8 MB/s eta 0:00:00\n",
            "Downloading sounddevice-0.4.6-py3-none-win_amd64.whl (199 kB)\n",
            "   ---------------------------------------- 0.0/199.7 kB ? eta -:--:--\n",
            "   --------------------------------------- 199.7/199.7 kB 11.8 MB/s eta 0:00:00\n",
            "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
            "   ---------------------------------------- 133.7/133.7 kB 8.2 MB/s eta 0:00:00\n",
            "Using cached opencv_contrib_python-4.9.0.80-cp37-abi3-win_amd64.whl (45.3 MB)\n",
            "Using cached cffi-1.16.0-cp38-cp38-win_amd64.whl (181 kB)\n",
            "Downloading ml_dtypes-0.2.0-cp38-cp38-win_amd64.whl (938 kB)\n",
            "   ---------------------------------------- 0.0/938.6 kB ? eta -:--:--\n",
            "   --------------------------------------- 938.6/938.6 kB 29.0 MB/s eta 0:00:00\n",
            "Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "   ---------------------------------------- 0.0/65.5 kB ? eta -:--:--\n",
            "   ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
            "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
            "Building wheels for collected packages: jax\n",
            "  Building wheel for jax (pyproject.toml): started\n",
            "  Building wheel for jax (pyproject.toml): finished with status 'done'\n",
            "  Created wheel for jax: filename=jax-0.4.13-py3-none-any.whl size=1518828 sha256=2494e6d119ed58b8d05a8bb33b3c76e8dc9b0e45318cfde420253653bc6e5c81\n",
            "  Stored in directory: c:\\users\\felicia\\appdata\\local\\pip\\cache\\wheels\\46\\d9\\15\\d2800d4089dc4c77299ac7513c6aa1036f5491edbd2bf6ba16\n",
            "Successfully built jax\n",
            "Installing collected packages: flatbuffers, pycparser, protobuf, opt-einsum, opencv-contrib-python, ml-dtypes, attrs, absl-py, jax, CFFI, sounddevice, mediapipe\n",
            "Successfully installed CFFI-1.16.0 absl-py-2.1.0 attrs-23.2.0 flatbuffers-24.3.25 jax-0.4.13 mediapipe-0.10.11 ml-dtypes-0.2.0 opencv-contrib-python-4.9.0.80 opt-einsum-3.3.0 protobuf-3.20.3 pycparser-2.22 sounddevice-0.4.6\n"
          ]
        }
      ],
      "source": [
        "!pip install mediapipe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a49D7h4TVmru"
      },
      "source": [
        "Then download an off-the-shelf model. Check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/face_detector#models) for more face detection models that you can use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OMjuVQiDYJKF"
      },
      "outputs": [],
      "source": [
        "!wget -q -O detector.tflite -q https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89BlskiiyGDC"
      },
      "source": [
        "## Visualization utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLHhoIkkWYLQ"
      },
      "source": [
        "To better demonstrate the Face Detector API, we have created a set of visualization tools that will be used in this colab. These will draw a bounding box around detected faces, as well as markers over certain detected points on the faces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "H4aPO-hvbw3r"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple, Union\n",
        "import math\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "MARGIN = 10  # pixels\n",
        "ROW_SIZE = 10  # pixels\n",
        "FONT_SIZE = 1\n",
        "FONT_THICKNESS = 1\n",
        "TEXT_COLOR = (255, 0, 0)  # red\n",
        "\n",
        "\n",
        "def _normalized_to_pixel_coordinates(\n",
        "    normalized_x: float, normalized_y: float, image_width: int,\n",
        "    image_height: int) -> Union[None, Tuple[int, int]]:\n",
        "  \"\"\"Converts normalized value pair to pixel coordinates.\"\"\"\n",
        "\n",
        "  # Checks if the float value is between 0 and 1.\n",
        "  def is_valid_normalized_value(value: float) -> bool:\n",
        "    return (value > 0 or math.isclose(0, value)) and (value < 1 or\n",
        "                                                      math.isclose(1, value))\n",
        "\n",
        "  if not (is_valid_normalized_value(normalized_x) and\n",
        "          is_valid_normalized_value(normalized_y)):\n",
        "    # TODO: Draw coordinates even if it's outside of the image bounds.\n",
        "    return None\n",
        "  x_px = min(math.floor(normalized_x * image_width), image_width - 1)\n",
        "  y_px = min(math.floor(normalized_y * image_height), image_height - 1)\n",
        "  return x_px, y_px\n",
        "\n",
        "\n",
        "def visualize(\n",
        "    image,\n",
        "    detection_result\n",
        ") -> np.ndarray:\n",
        "  \"\"\"Draws bounding boxes and keypoints on the input image and return it.\n",
        "  Args:\n",
        "    image: The input RGB image.\n",
        "    detection_result: The list of all \"Detection\" entities to be visualize.\n",
        "  Returns:\n",
        "    Image with bounding boxes.\n",
        "  \"\"\"\n",
        "  annotated_image = image.copy()\n",
        "  height, width, _ = image.shape\n",
        "\n",
        "  for detection in detection_result.detections:\n",
        "    # Draw bounding_box\n",
        "    bbox = detection.bounding_box\n",
        "    start_point = bbox.origin_x, bbox.origin_y\n",
        "    end_point = bbox.origin_x + bbox.width, bbox.origin_y + bbox.height\n",
        "    cv2.rectangle(annotated_image, start_point, end_point, TEXT_COLOR, 3)\n",
        "\n",
        "    # Draw keypoints\n",
        "    for keypoint in detection.keypoints:\n",
        "      keypoint_px = _normalized_to_pixel_coordinates(keypoint.x, keypoint.y,\n",
        "                                                     width, height)\n",
        "      color, thickness, radius = (0, 255, 0), 2, 2\n",
        "      cv2.circle(annotated_image, keypoint_px, thickness, color, radius)\n",
        "\n",
        "    # Draw label and score\n",
        "    category = detection.categories[0]\n",
        "    category_name = category.category_name\n",
        "    category_name = '' if category_name is None else category_name\n",
        "    probability = round(category.score, 2)\n",
        "    result_text = category_name + ' (' + str(probability) + ')'\n",
        "    text_location = (MARGIN + bbox.origin_x,\n",
        "                     MARGIN + ROW_SIZE + bbox.origin_y)\n",
        "    cv2.putText(annotated_image, result_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
        "                FONT_SIZE, TEXT_COLOR, FONT_THICKNESS)\n",
        "\n",
        "  return annotated_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83PEJNp9yPBU"
      },
      "source": [
        "## Download test image\n",
        "\n",
        "To demonstrate Face Detection, you can download a sample image using the following code. Credits: https://pixabay.com/photos/brother-sister-girl-family-boy-977170/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tzXuqyIBlXer"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'cv2_imshow' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m IMAGE_FILE \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(source_dir, imgname)\n\u001b[0;32m      9\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(IMAGE_FILE)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mcv2_imshow\u001b[49m(img)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'cv2_imshow' is not defined"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "source_dir = \"../datasets/event_20240405_18_06_48_fps1_clip_1_0/color_original\"\n",
        "color_files = sorted([f for f in os.listdir(source_dir)])\n",
        "\n",
        "for imgname in color_files:\n",
        "\n",
        "    IMAGE_FILE = os.path.join(source_dir, imgname)\n",
        "    img = cv2.imread(IMAGE_FILE)\n",
        "    cv2.imshow('', img)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAFQm3HHi5OG"
      },
      "source": [
        "Optionally, you can upload your own image from your computer. To do this, uncomment the following code cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gwip05yi6lV"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for filename in uploaded:\n",
        "#   content = uploaded[filename]\n",
        "#   with open(filename, 'wb') as f:\n",
        "#     f.write(content)\n",
        "\n",
        "# if len(uploaded.keys()):\n",
        "#   IMAGE_FILE = next(iter(uploaded))\n",
        "#   print('Uploaded file:', IMAGE_FILE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy4r2_ePylIa"
      },
      "source": [
        "## Running inference and visualizing the results\n",
        "\n",
        "The final step is to run face detection on your selected image. This involves creating your FaceDetector object, loading your image, running detection, and finally, the optional step of displaying the image with visualizations.\n",
        "\n",
        "You can check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/face_detector/python) to learn more about configuration options that this solution supports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl_Oiye4mUuo"
      },
      "outputs": [],
      "source": [
        "# STEP 1: Import the necessary modules.\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from mediapipe.tasks import python\n",
        "from mediapipe.tasks.python import vision\n",
        "\n",
        "# STEP 2: Create an FaceDetector object.\n",
        "base_options = python.BaseOptions(model_asset_path='detector.tflite')\n",
        "options = vision.FaceDetectorOptions(base_options=base_options)\n",
        "detector = vision.FaceDetector.create_from_options(options)\n",
        "\n",
        "# STEP 3: Load the input image.\n",
        "image = mp.Image.create_from_file(IMAGE_FILE)\n",
        "\n",
        "# STEP 4: Detect faces in the input image.\n",
        "detection_result = detector.detect(image)\n",
        "\n",
        "# STEP 5: Process the detection result. In this case, visualize it.\n",
        "image_copy = np.copy(image.numpy_view())\n",
        "annotated_image = visualize(image_copy, detection_result)\n",
        "rgb_annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
        "cv2_imshow(rgb_annotated_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNJq-ygtZX7J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
